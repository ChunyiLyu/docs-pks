---
title: Manage Users in UAA
owner: PKS
---

<strong><%= modified_date %></strong>

This topic describes how to manage users in Pivotal Container Service (PKS) with User Account and Authentication (UAA).
Create and manage users in UAA with the UAA Command Line Interface (UAAC).

## <a id='uaac'></a>How to Use UAAC

Use the UAA Command Line Interface (UAAC) to interact with the UAA server.
You can either run UAAC commands from the Ops Manager VM or install UAAC on your local workstation.

To run UAAC commands from the Ops Manager VM, see the following SSH procedures for [vSphere](#ssh-vsphere) or [Google Cloud Platform (GCP)](#ssh-gcp).

To install UAAC locally, see [Component: User Account and Authentication (UAA) Server](https://docs.pivotal.io/pivotalcf/concepts/architecture/uaa.html).

### <a id='ssh-vsphere'></a>SSH into the Ops Manager VM on vSphere

To SSH into the Ops Manager VM on vSphere, you need the credentials used to import the PCF .ova or .ovf file into your virtualization system.
You set these credentials when you installed Ops Manager.

<p class="note"><strong>Note</strong>: If you lose your credentials, you must shut down the Ops Manager VM in the vSphere UI and reset the password. See <a href="https://docs.vmware.com/en/VMware-vSphere/6.5/com.vmware.vsphere.security.doc/GUID-4BDBF79A-6C16-43B0-B0B1-637BF5516112.html">vCenter Password Requirements and Lockout Behavior</a> in the vSphere documentation for more information.</p>

1. From a command line, run `ssh ubuntu@OPS-MANAGER-FQDN` to SSH into the Ops Manager VM.
Replace `OPS-MANAGER-FQDN` with the fully qualified domain name of Ops Manager.

1. When prompted, enter the password that you set during the .ova deployment
into vCenter. For example:
  <pre class="terminal">
  $ ssh ubuntu&#64;my-opsmanager-fqdn.example.com
  Password: ***********
  </pre>

1. Proceed to the [Retrieve UAA Admin Credentials](#uaa-admin) section to manage users with UAAC.

### <a id='ssh-gcp'></a>SSH into the Ops Manager VM on GCP

To SSH into the Ops Manager VM in GCP, follow these instructions:

1. Confirm that you have installed the gcloud CLI. See the [Google Cloud Platform documentation](https://cloud.google.com/sdk/gcloud/#downloading_gcloud) for more information.

1. From the GCP console, click **Compute Engine**.

1. Locate the Ops Manager VM in the **VM Instances** list.

1. Click the **SSH** menu button.

1. Copy the SSH command that appears in the popup window.

1. Paste the command into your terminal window to SSH to the Ops Manager VM. For example:
    <pre class="terminal">
    $ gcloud compute ssh om-pcf-1a --zone us-central1-b
    </pre>

1. Run `sudo su - ubuntu` to switch to the `ubuntu` user.

1. Proceed to the [Retrieve UAA Admin Credentials](#uaa-admin) section to manage users with UAAC.

##<a id='uaa-admin-login'></a> Log in as an Admin

To retrieve the PKS UAA management admin client secret, do the following:

1. In a web browser, navigate to the fully qualified domain name (FQDN) of Ops Manager and click the **Pivotal Container Service** tile.
1. Click **Credentials**.
1. To view the secret, click **Link to Credential** next to **Pks Uaa Management Admin Client**. The client username is `admin`.
1. On the command line, run the following command to target your UAA server:
  <pre>`uaac target https://PKS-API:8443 --ca-cert ROOT-CA-FILENAME`</pre>
  Replace `PKS-API` with the URL to your PKS API server. You configured this URL in the PKS API section of _Installing PKS_ for your IaaS. For example, see [Installing PKS on vSphere](installing-pks-vsphere.html#pks-api). Replace `ROOT-CA-FILENAME` with the certificate file you downloaded in [Configure Access to the PKS API](configure-api.html#access).
  For example:
    <pre class="terminal">
    $ uaac target api.pks.example.com:8443 --ca-cert my-cert.cert
    </pre>

    <p class="note"><strong>Note</strong>: If you receive an <code>Unknown key: Max-Age = 86400</code> warning message, you can safely ignore it because it has no impact.</p>

1. Authenticate with UAA using the secret you retrieved in a previous step.
Run the following command, replacing `ADMIN-CLIENT-SECRET` with your PKS UAA management admin client secret: <pre>uaac token client get admin -s ADMIN-CLIENT-SECRET</pre>

##<a id='cluster-access'></a> Grant Cluster Access

You can assign the following UAA scopes to users, external LDAP groups, and clients:

  * `pks.clusters.manage`: accounts with this scope can create and access their own clusters.
  * `pks.clusters.admin`: accounts with this scope can create and access all clusters.

###<a id='uaa-user'></a> Grant Cluster Access to a User

To create a new UAA user with cluster access, perform the following steps:

1. Log in as the UAA admin using the procedure [above](#uaa-admin-login).

1. To create a new user, run the following command:
  <pre>uaac user add USERNAME --emails USER-EMAIL -p USER-PASSWORD</pre>

    For example:
    <pre class="terminal">$ uaac user add alana --emails alana&#64;example.com -p password</pre>

1. Assign a scope to the user to allow them to access Kubernetes clusters.
Run `uaac member add UAA-SCOPE USERNAME`, replacing `UAA-SCOPE` with one of the UAA scopes defined [above](#cluster-access).
For example:
    <pre class="terminal">$ uaac member add pks.clusters.admin alana</pre>

###<a id='external-group'></a> Grant Control Plane Access to an External LDAP Group

Connecting PKS to a LDAP external user store allows the User Account and Authentication (UAA) server to delegate authentication to existing enterprise user stores.

<p class='note'><strong>Note</strong>: When integrating with an external identity provider such as LDAP, authentication within the UAA becomes chained.
UAA first attempts to authenticate with a user's credentials against the UAA user store before the external provider, LDAP.
For more information, see <a href="https://github.com/cloudfoundry/uaa/blob/master/docs/UAA-LDAP.md#chained-authentication">Chained Authentication</a> in the <em>User Account and Authentication LDAP Integration</em> GitHub documentation.
</p>

For more information about the process used by the UAA Server when it attempts to authenticate a user through LDAP, see the [Configuring LDAP Integration with Pivotal Cloud Foundry](https://discuss.zendesk.com/hc/en-us/articles/204140418-Configuring-LDAP-Integration-with-Pivotal-Cloud-Foundry-) Knowledge Base article.

The PKS control plane enables users to deploy and manage Kubernetes clusters.

To grant control plane access to an external LDAP group, perform the following steps:

1. Log in as the UAA admin using the procedure [above](#uaa-admin-login).

1. To assign the `pks.clusters.manage` scope to all users in an LDAP group, run the following command:
  <pre>uaac group map --name pks.clusters.manage GROUP-DISTINGUISHED-NAME</pre>
Replace `GROUP-DISTINGUISHED-NAME` with the LDAP Distinguished Name (DN) for the group.
For example:
    <pre class="terminal">
    $ uaac group map --name pks.clusters.manage cn=operators,ou=groups,dc=example,dc=com
    </pre>
    For more information about LDAP DNs, see the LDAP [documentation](https://ldap.com/ldap-dns-and-rdns/).

1. (Optional) To assign the `pks.clusters.admin` scope to all users in an LDAP group, run the following command:
  <pre>uaac group map --name pks.clusters.admin GROUP-DISTINGUISHED-NAME</pre>
Replace `GROUP-DISTINGUISHED-NAME` with the LDAP DN for the group.
For example:
    <pre class="terminal">
    $ uaac group map --name pks.clusters.admin cn=operators,ou=groups,dc=example,dc=com
    </pre>

###<a id='uaa-client'></a> Grant Cluster Access to a Client

To grant cluster access to an automated client for a script or service, perform the following steps:

1. Log in as the UAA admin using the procedure [above](#uaa-admin-login).

1. Create a client with the desired scopes by running the following command:
  <pre>uaac client add CLIENT-NAME -s CLIENT-SECRET \
  --authorized&#95;grant&#95;types client&#95;credentials \
  --authorities UAA-SCOPES</pre>
  Replace `CLIENT-NAME` and `CLIENT-SECRET` with the client credentials. Replace `UAA-SCOPES` with one or more of the UAA scopes defined [above](#cluster-access), separated by a comma. For example:
    <pre class="terminal">$ uaac client add automated-client \
    -s randomly-generated-secret
    --authorized&#95;grant&#95;types client&#95;credentials  \
    --authorities pks.clusters.admin,pks.clusters.manage</pre>

###<a id='access-other-users'></a> Granting Cluster Access to Other Users

Admin Users with the `pks.clusters.admin` or `pks.clusters.manage` scope can grant cluster-wide access to other users who do not have either the `pks.clusters.admin` or `pks.clusters.manage` scopes. 

To do this, the Admin User creates a `clusterRoleBinding` for those other users. For more information on cluster role bindings, see [RoleBinding and ClusterRoleBinding](https://kubernetes.io/docs/reference/access-authn-authz/rbac/#rolebinding-and-clusterrolebinding) in the Kubernetes documentation.

At the end of this process, the non-Admin user is able to use the Kubernetes Command Line Interface (kubectl) to connect to the cluster and deploy their workloads. The non-admin users cannot resize or delete clusters. 

<p class='note'><strong>Note</strong>: In order for Admin Users to grant cluster-wide access to non-Admin users, Admin users must ensure that they have selected <b>Enable UAA as OIDC provider</b> in the UAA section of the PKS tile.
</p>

To give cluster-wide access, the Admin User must perform the following actions:

1. Log in as a UAA Admin User using the procedure [above](#uaa-admin-login).

1. Run the following command to confirm that you can successfully connect to a cluster and use kubectl as an Admin User:
<pre class="terminal">$ pks get-credentials CLUSTER-NAME</pre>
This step also creates a `clusterRoleBinding` for the UAA admin with the `pks.clusters.admin` and `pks.clusters.manage` scopes. [comment:The above creates a cluster rolebinding for the admin but the point of this is for the admin to create a cluster rolebinding for the user]

1. Create a spec YML file containing a `clusteRroleBinding` with the appropriate `roleRef` for the non-Admin user. For reference, review the example spec file below:
  Where:
  <ul>
    <li> `NAME-OF-CLUSTER-ROLEBINDING` is the name of your `clusterRoleBinding`.
    <li> `NAME-OF-USER` is the user's UAA username.
    <li> `ROLE-REF` is your selected `roleRef`.
  </ul>

  <pre>
  kind: ClusterRoleBinding
  apiVersion: rbac.authorization.k8s.io/v1
  metadata:
    name: NAME-OF-CLUSTER-ROLEBINDING
  subjects:
  - kind: User
    name: NAME-OF-USER # Name is case sensitive
    apiGroup: rbac.authorization.k8s.io
  roleRef:
    kind: ClusterRole
    name: ROLE-REF
    apiGroup: rbac.authorization.k8s.io
  </pre>

  It is also possible to create ClusterRoleBinding for groups of users. This is only available if LDAP is used as Identity Provider for UAA.
  <ul>
    <li> `NAME-OF-CLUSTER-ROLEBINDING` is the name of your `clusterRoleBinding`.
    <li> `NAME-OF-GROUP` is the LDAP group name. 
    <li> `ROLE-REF` is your selected `roleRef`.
  </ul>

<p class='note'><strong>Note</strong>: You must confirm that the group you are referencing in your <code>clusterRoleBinding</code> has been whitelisted in the PKS tile. To do so, review the **External Groups Whitelist** field in the UAA section of the PKS tile.
</p>

  <pre>
  kind: ClusterRoleBinding
  apiVersion: rbac.authorization.k8s.io/v1
  metadata:
    name: NAME-OF-GROUP-CLUSTER-ROLEBINDING
  subjects:
  - kind: Group
    name: NAME-OF-GROUP # Name is case sensitive
    apiGroup: rbac.authorization.k8s.io
  roleRef:
    kind: ClusterRole
    name: ROLE-REF
    apiGroup: rbac.authorization.k8s.io
  </pre>

1. Run the following command to create the above defined `clusterRoleBinding` in the cluster:
<pre class="terminal">$ kubectl apply -f spec.yml</pre>

1. The Admin User creates a partially completed `kubeconfig` detailing the following: 
  + `clusters.cluster.certificate-authority-data`
  + `clusters.cluster.server`
  + `cluster.name`
  + `contexts.context.cluster`
  + `contexts.context.name`
  + `current-context`
  + `users.user.auth-provider.config.idp-issuer-url`

To finish the process, the non-Admin user must perform the following tasks:

1. After receiving the `kubeconfig` from the Admin User, the following parameters are entered by the non-Admin user:
  + `contexts.context.user`
  + `users.name`
  + `users.user.auth-provider.config.id-token`
  + `users.user.auth-provider.config.refresh-token`

1. To obtain `users.user.auth-provider.config.id-token` and `users.user.auth-provider.config.refresh-token` the non-Admin user runs following command:
<pre class="terminal">
$ curl '<span>https:</span>//PKS-API>:8443/oauth/token' -k -XPOST -H 'Accept: application/json' -d "client_id=pks_cluster_client&client_secret=""&grant_type=password&username=UAA-USERNAME&password=UAA-PASSWORD&response_type=id_token"
</pre>
Where:
<ul>
  <li>`PKS-API` is the fully qualified domain name (FQDN) you use to access the PKS API.
  <li>`UAA-USERNAME` is the non-Admin user's UAA username.
  <li>`UAA-PASSWORD` is the non-Admin user's UAA password. 
</ul>
1. From the output of the above command, add the `id_token` and `refresh_token` values to the kubeconfig.
1. Save kubeconfig to `$HOME/.kube/config` directory. After doing so, the non-Admin User can connect to the cluster using `kubectl`. 

For reference, review example kubeconfig file below. For more information about organizing information using kubeconfig, see [Organizing Cluster Access Using kubeconfig Files](https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/) in the Kubernetes documentation.
<pre>
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: PROVIDED-BY-ADMIN
    server: PROVIDED-BY-ADMIN
  name: PROVIDED-BY-ADMIN
contexts:
- context:
    cluster: PROVIDED-BY-ADMIN
    user: PROVIDED-BY-USER
  name:  PROVIDED-BY-ADMIN
current-context: PROVIDED-BY-ADMIN
kind: Config
preferences: {}
users:
- name:  PROVIDED-BY-USER
  user: 
    auth-provider:
      config:
        client-id: pks_cluster_client
        cluster_client_secret: ""
        id-token: PROVIDED-BY-USER
        idp-issuer-url: <span>https:</span>//PROVIDED-BY-ADMIN:8443/oauth/token
        refresh-token:  PROVIDED-BY-USER
      name: oidc
</pre>
